# ğŸš€ Tutorial: Adaptando o Framework para Seu Novo Projeto

Este guia passo a passo mostra como adaptar este framework de Data Science para seu prÃ³prio projeto, seja de classificaÃ§Ã£o, regressÃ£o ou outro tipo de problema de Machine Learning.

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral do Framework](#visÃ£o-geral-do-framework)
2. [PreparaÃ§Ã£o Inicial](#preparaÃ§Ã£o-inicial)
3. [AdaptaÃ§Ã£o Passo a Passo](#adaptaÃ§Ã£o-passo-a-passo)
4. [Exemplos PrÃ¡ticos](#exemplos-prÃ¡ticos)
5. [Checklist Final](#checklist-final)

---

## ğŸ“Š VisÃ£o Geral do Framework

### Estrutura Modular

O framework estÃ¡ organizado em mÃ³dulos independentes e reutilizÃ¡veis:

```
Entrada de Dados â†’ Preprocessamento â†’ Feature Engineering â†’ 
Treinamento â†’ AvaliaÃ§Ã£o â†’ Monitoramento â†’ InferÃªncia
```

### Componentes Principais

| Componente | Arquivo | FunÃ§Ã£o |
|------------|---------|--------|
| **ConfiguraÃ§Ã£o** | `src/config.py` | ParÃ¢metros centralizados |
| **Preprocessamento** | `src/preprocessing.py` | Limpeza e divisÃ£o de dados |
| **Features** | `src/features.py` | TransformaÃ§Ãµes e encoding |
| **Treinamento** | `src/train.py` | Treinamento e CV |
| **AvaliaÃ§Ã£o** | `src/evaluate.py` | MÃ©tricas e relatÃ³rios |
| **InferÃªncia** | `src/inference.py` | PrediÃ§Ãµes em produÃ§Ã£o |
| **Monitoramento** | `src/monitoring.py` | DetecÃ§Ã£o de drift |
| **Logging** | `src/logger.py` | Logs estruturados |

---

## ğŸ¯ PreparaÃ§Ã£o Inicial

### 1. Clone ou Fork do RepositÃ³rio

```bash
# OpÃ§Ã£o 1: Clone direto
git clone <seu-repo>
cd modelo_projetos_ds

# OpÃ§Ã£o 2: Use como template
# No GitHub: Use this template â†’ Create a new repository

# Renomeie para seu projeto
mv modelo_projetos_ds meu_projeto_ml
cd meu_projeto_ml
```

### 2. Configure o Ambiente

```bash
# Instale Poetry (se nÃ£o tiver)
curl -sSL https://install.python-poetry.org | python3 -

# Instale dependÃªncias
poetry install

# Ative o ambiente
poetry shell
```

### 3. Limpe Dados de Exemplo

```bash
# Remova dados de exemplo (mantenha estrutura)
rm -f data/raw/*.csv
rm -f data/processed/*.csv
rm -rf mlruns/*

# Limpe notebooks de exemplo (ou adapte-os)
# (Opcional) Mantenha-os como referÃªncia
```

---

## ğŸ”§ AdaptaÃ§Ã£o Passo a Passo

### PASSO 1: ConfiguraÃ§Ã£o Base (`src/config.py`)

**O que mudar:**

```python
# ==================== CONFIGURAÃ‡ÃƒO DO PROJETO ====================
PROJECT_NAME = "meu_projeto"  # â† MUDE AQUI
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# ==================== CONFIGURAÃ‡ÃƒO DE DADOS ====================
TARGET = "sua_coluna_target"  # â† Nome da coluna alvo
TEST_SIZE = 0.2              # â† % para teste (0.2 = 20%)
RANDOM_STATE = 42            # â† Seed para reprodutibilidade

# ==================== CAMINHOS ====================
DATA_DIR = os.path.join(BASE_DIR, "data")
RAW_DATA_PATH = os.path.join(DATA_DIR, "raw", "seus_dados.csv")  # â† MUDE
PROCESSED_DATA_PATH = os.path.join(DATA_DIR, "processed", "data.csv")
MODEL_PATH = os.path.join(BASE_DIR, "models", "model.pkl")

# ==================== MLFLOW ====================
MLFLOW_TRACKING_URI = os.path.join(BASE_DIR, "mlruns")
MLFLOW_EXPERIMENT = "meu_experimento"  # â† Nome do experimento
MODEL_NAME = "seu_modelo"              # â† Nome do modelo
```

**Exemplo para classificaÃ§Ã£o de clientes:**

```python
PROJECT_NAME = "customer_churn"
TARGET = "churn"
MLFLOW_EXPERIMENT = "churn_prediction"
MODEL_NAME = "churn_classifier"
```

### PASSO 2: ParÃ¢metros do Modelo

**Para ClassificaÃ§Ã£o (XGBoost):**

```python
MODEL_PARAMS = {
    "n_estimators": 300,
    "max_depth": 6,
    "learning_rate": 0.05,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "random_state": RANDOM_STATE,
    "eval_metric": "logloss"  # ou "auc", "error"
}
```

**Para RegressÃ£o:**

```python
from xgboost import XGBRegressor  # Em src/train.py

MODEL_PARAMS = {
    "n_estimators": 300,
    "max_depth": 6,
    "learning_rate": 0.05,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "random_state": RANDOM_STATE,
    "eval_metric": "rmse"  # ou "mae"
}
```

**Para usar outro algoritmo (exemplo: Random Forest):**

```python
# Em src/train.py, substitua:
from sklearn.ensemble import RandomForestClassifier

# E em train_model():
model = RandomForestClassifier(
    n_estimators=params.get("n_estimators", 100),
    max_depth=params.get("max_depth", 10),
    random_state=params.get("random_state", 42)
)
```

### PASSO 3: Features e Preprocessamento (`src/features.py`)

**Identifique suas features:**

```python
# No seu script de anÃ¡lise ou notebook
import pandas as pd

df = pd.read_csv("data/raw/seus_dados.csv")

# Separe por tipo
numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()

# Remova o target
numeric_features.remove('seu_target')  # se for numÃ©rico

print("Features numÃ©ricas:", numeric_features)
print("Features categÃ³ricas:", categorical_features)
```

**Adapte o preprocessador:**

```python
# src/features.py - funÃ§Ã£o build_preprocessor()

def build_preprocessor(numeric_features, categorical_features):
    """
    CUSTOMIZE AQUI:
    - Adicione transformaÃ§Ãµes especÃ­ficas
    - Mude estratÃ©gias de imputaÃ§Ã£o
    - Adicione feature scaling diferente
    """
    
    # Pipeline numÃ©rico
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),  # ou 'mean', 'most_frequent'
        ('scaler', StandardScaler())  # ou MinMaxScaler(), RobustScaler()
    ])
    
    # Pipeline categÃ³rico
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
        # Alternativa: LabelEncoder, TargetEncoder, etc.
    ])
    
    # Combine
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features)
        ])
    
    return preprocessor
```

### PASSO 4: MÃ©tricas de AvaliaÃ§Ã£o (`src/evaluate.py`)

**Para ClassificaÃ§Ã£o BinÃ¡ria (jÃ¡ implementado):**

```python
# MantÃ©m como estÃ¡
- ROC-AUC
- Precision, Recall, F1-Score
- Classification Report
```

**Para ClassificaÃ§Ã£o Multiclasse:**

```python
# src/evaluate.py - adapte a funÃ§Ã£o evaluate()

# Adicione average='weighted' ou 'macro'
from sklearn.metrics import roc_auc_score, classification_report

# Para multiclasse com probabilidades
roc_auc = roc_auc_score(y_test, proba, multi_class='ovr', average='weighted')
```

**Para RegressÃ£o:**

```python
# src/evaluate.py - SUBSTITUA a funÃ§Ã£o evaluate()

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

def evaluate(model, X_test, y_test):
    """Avalia modelo de regressÃ£o."""
    logger.info(f"Iniciando avaliaÃ§Ã£o com {X_test.shape[0]} amostras")
    
    preds = model.predict(X_test)
    
    # MÃ©tricas de regressÃ£o
    mse = mean_squared_error(y_test, preds)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, preds)
    r2 = r2_score(y_test, preds)
    
    # Log no MLflow
    mlflow.log_metrics({
        "mse": mse,
        "rmse": rmse,
        "mae": mae,
        "r2_score": r2
    })
    
    logger.info("AvaliaÃ§Ã£o concluÃ­da", extra={
        'rmse': rmse,
        'mae': mae,
        'r2': r2
    })
    
    return {
        "mse": mse,
        "rmse": rmse,
        "mae": mae,
        "r2_score": r2
    }
```

### PASSO 5: Carregamento de Dados

**OpÃ§Ã£o A: CSV local**

```python
# scripts/run_pipeline.py ou seu script principal

import pandas as pd
from src.config import RAW_DATA_PATH, TARGET

# Carregue seus dados
df = pd.read_csv(RAW_DATA_PATH)

# Separe features e target
X = df.drop(columns=[TARGET])
y = df[TARGET]
```

**OpÃ§Ã£o B: Banco de dados**

```python
# Adicione ao pyproject.toml:
# sqlalchemy = "^2.0"
# psycopg2-binary = "^2.9"  # para PostgreSQL

import sqlalchemy as sa

# Crie conexÃ£o
engine = sa.create_engine('postgresql://user:pass@localhost/dbname')

# Carregue dados
query = "SELECT * FROM sua_tabela"
df = pd.read_sql(query, engine)
```

**OpÃ§Ã£o C: API**

```python
import requests
import pandas as pd

response = requests.get('https://api.example.com/data')
data = response.json()
df = pd.DataFrame(data)
```

### PASSO 6: Scripts de Pipeline

**Adapte `scripts/run_pipeline.py`:**

```python
from src.config import *
from src.preprocessing import split_data
from src.features import build_preprocessor
from src.train import train_model, save_model
from src.evaluate import evaluate
import pandas as pd
import mlflow

def main():
    mlflow.set_tracking_uri(f"file://{MLFLOW_TRACKING_URI}")
    mlflow.set_experiment(MLFLOW_EXPERIMENT)
    
    # 1. CARREGUE SEUS DADOS (customize aqui)
    df = pd.read_csv(RAW_DATA_PATH)
    
    # 2. IDENTIFIQUE FEATURES (customize)
    numeric_features = ['idade', 'renda', 'score']  # â† SEUS DADOS
    categorical_features = ['estado', 'categoria']  # â† SEUS DADOS
    
    # 3. SPLIT (usa sua config)
    X_train, X_test, y_train, y_test = split_data(
        df, target=TARGET, test_size=TEST_SIZE, random_state=RANDOM_STATE
    )
    
    # 4. PREPROCESSAMENTO
    preprocessor = build_preprocessor(numeric_features, categorical_features)
    
    # 5. TREINAMENTO
    with mlflow.start_run(run_name="production_run"):
        pipeline = train_model(preprocessor, X_train, y_train)
        
        # 6. AVALIAÃ‡ÃƒO
        metrics = evaluate(pipeline, X_test, y_test)
        
        # 7. SALVAR MODELO
        save_model(pipeline, X_example=X_test)
        
        print(f"âœ… Pipeline completo! MÃ©tricas: {metrics}")

if __name__ == "__main__":
    main()
```

### PASSO 7: Testes

**Adapte fixtures em `tests/conftest.py`:**

```python
import pytest
import pandas as pd
import numpy as np

@pytest.fixture
def sample_data():
    """Crie dados de exemplo do SEU domÃ­nio."""
    np.random.seed(42)
    
    return pd.DataFrame({
        'feature1': np.random.randn(100),
        'feature2': np.random.randn(100),
        'category': np.random.choice(['A', 'B', 'C'], 100),
        'target': np.random.randint(0, 2, 100)  # Para classificaÃ§Ã£o
        # ou: 'target': np.random.randn(100) * 10 + 50  # Para regressÃ£o
    })

@pytest.fixture
def preprocessor_features():
    """Features do seu projeto."""
    return {
        "numeric_features": ['feature1', 'feature2'],
        "categorical_features": ['category']
    }
```

**Execute testes:**

```bash
# Teste individual
poetry run pytest tests/test_preprocessing.py -v

# Todos os testes
poetry run pytest tests/ -v

# Com cobertura
poetry run pytest --cov=src --cov-report=html
```

---

## ğŸ’¡ Exemplos PrÃ¡ticos

### Exemplo 1: ClassificaÃ§Ã£o de Churn

```python
# config.py
PROJECT_NAME = "customer_churn"
TARGET = "churn"
MLFLOW_EXPERIMENT = "churn_prediction"

# Suas features
NUMERIC_FEATURES = [
    'tenure', 'monthly_charges', 'total_charges',
    'num_services', 'contract_months'
]

CATEGORICAL_FEATURES = [
    'gender', 'senior_citizen', 'partner', 'dependents',
    'phone_service', 'internet_service', 'contract_type'
]

# Modelo
MODEL_PARAMS = {
    "n_estimators": 300,
    "max_depth": 6,
    "learning_rate": 0.05,
    "scale_pos_weight": 3,  # Para dados desbalanceados
    "eval_metric": "logloss"
}
```

### Exemplo 2: PrevisÃ£o de PreÃ§os (RegressÃ£o)

```python
# config.py
PROJECT_NAME = "house_prices"
TARGET = "price"
MLFLOW_EXPERIMENT = "price_prediction"

# Suas features
NUMERIC_FEATURES = [
    'area', 'bedrooms', 'bathrooms', 'age',
    'distance_center', 'floor'
]

CATEGORICAL_FEATURES = [
    'neighborhood', 'type', 'condition'
]

# Modelo (regressÃ£o)
from xgboost import XGBRegressor

MODEL_PARAMS = {
    "n_estimators": 500,
    "max_depth": 8,
    "learning_rate": 0.01,
    "eval_metric": "rmse"
}
```

### Exemplo 3: ClassificaÃ§Ã£o Multiclasse

```python
# config.py
PROJECT_NAME = "product_category"
TARGET = "category"
MLFLOW_EXPERIMENT = "category_classification"

# Modelo (multiclasse)
MODEL_PARAMS = {
    "n_estimators": 300,
    "max_depth": 6,
    "learning_rate": 0.05,
    "objective": "multi:softprob",  # â† Para multiclasse
    "num_class": 5,  # â† NÃºmero de classes
    "eval_metric": "mlogloss"
}
```

---

## âœ… Checklist Final

### Antes de Treinar

- [ ] **Config atualizada**: `src/config.py` com seus parÃ¢metros
- [ ] **Dados carregados**: CSV, DB ou API funcionando
- [ ] **Features identificadas**: Listas de numeric/categorical
- [ ] **Target correto**: Nome da coluna alvo no config
- [ ] **Preprocessador adaptado**: TransformaÃ§Ãµes adequadas ao seu caso
- [ ] **Modelo escolhido**: XGBoost, RF, ou outro
- [ ] **MÃ©tricas corretas**: ClassificaÃ§Ã£o vs RegressÃ£o

### ValidaÃ§Ã£o

```bash
# 1. Teste preprocessamento
poetry run python -c "
from src.features import build_preprocessor
from src.config import *
import pandas as pd

df = pd.read_csv(RAW_DATA_PATH)
# ... teste suas features
print('âœ… Preprocessamento OK')
"

# 2. Teste pipeline completo
poetry run python scripts/test_pipeline.py

# 3. Rode CI local
./test_ci_locally.sh
```

### Deploy e ProduÃ§Ã£o

- [ ] **Testes passando**: >80% cobertura
- [ ] **MLflow configurado**: Experimentos rodando
- [ ] **Dashboard funcionando**: `streamlit run scripts/dashboard.py`
- [ ] **Monitoramento ativo**: Drift detection configurado
- [ ] **DocumentaÃ§Ã£o atualizada**: README do seu projeto
- [ ] **CI/CD configurado**: GitHub Actions funcionando

---

## ğŸ¨ CustomizaÃ§Ãµes AvanÃ§adas

### Adicionar Feature Engineering

```python
# src/features.py - adicione transformadores customizados

from sklearn.base import BaseEstimator, TransformerMixin

class CustomFeatureExtractor(BaseEstimator, TransformerMixin):
    """Extrai features especÃ­ficas do seu domÃ­nio."""
    
    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        X = X.copy()
        # Suas transformaÃ§Ãµes
        X['feature_ratio'] = X['num1'] / (X['num2'] + 1e-10)
        X['feature_interaction'] = X['cat1'] + '_' + X['cat2']
        return X

# Use no preprocessador
preprocessor = ColumnTransformer([
    ('custom', CustomFeatureExtractor(), slice(None)),
    ('num', numeric_transformer, numeric_features),
    ('cat', categorical_transformer, categorical_features)
])
```

### Adicionar ValidaÃ§Ã£o de Schema

```python
# Adicione pandera para validaÃ§Ã£o
# poetry add pandera

import pandera as pa

# Defina schema
schema = pa.DataFrameSchema({
    "idade": pa.Column(int, pa.Check.in_range(0, 120)),
    "renda": pa.Column(float, pa.Check.greater_than(0)),
    "categoria": pa.Column(str, pa.Check.isin(['A', 'B', 'C']))
})

# Valide dados
df = schema.validate(df)
```

### Adicionar SeleÃ§Ã£o de Features

```python
# src/features.py

from sklearn.feature_selection import SelectKBest, f_classif

# No preprocessador
preprocessor = Pipeline([
    ('preprocessing', column_transformer),
    ('feature_selection', SelectKBest(f_classif, k=20))  # Top 20 features
])
```

---

## ğŸš‘ Troubleshooting Comum

### Problema: Erro de dimensÃ£o de features

**Causa:** Features do treino â‰  features da inferÃªncia

**SoluÃ§Ã£o:**
```python
# Salve a lista de features junto com o modelo
import joblib

joblib.dump({
    'model': pipeline,
    'numeric_features': numeric_features,
    'categorical_features': categorical_features
}, 'models/model_with_features.pkl')
```

### Problema: Dados desbalanceados

**SoluÃ§Ã£o:**
```python
# OpÃ§Ã£o 1: Use class_weight
MODEL_PARAMS = {
    # ... outros params
    "scale_pos_weight": sum(y == 0) / sum(y == 1)  # Para XGBoost
}

# OpÃ§Ã£o 2: Use SMOTE (poetry add imbalanced-learn)
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)
```

### Problema: Overfitting

**SoluÃ§Ã£o:**
```python
# RegularizaÃ§Ã£o mais forte
MODEL_PARAMS = {
    "n_estimators": 100,  # Menos Ã¡rvores
    "max_depth": 4,       # Ãrvores mais rasas
    "learning_rate": 0.01, # Learning rate menor
    "subsample": 0.7,     # Mais agressivo
    "colsample_bytree": 0.7,
    "reg_alpha": 1.0,     # L1 regularization
    "reg_lambda": 1.0     # L2 regularization
}
```

---

## ğŸ“ Suporte e Recursos

### Recursos Adicionais

- **DocumentaÃ§Ã£o Scikit-learn**: https://scikit-learn.org/
- **DocumentaÃ§Ã£o XGBoost**: https://xgboost.readthedocs.io/
- **MLflow Guide**: https://mlflow.org/docs/latest/
- **Pytest Documentation**: https://docs.pytest.org/

### PrÃ³ximos Passos Recomendados

1. **Comece simples**: Use o exemplo de classificaÃ§Ã£o binÃ¡ria
2. **Valide incrementalmente**: Teste cada mÃ³dulo isoladamente
3. **Use notebooks**: Explore seus dados primeiro
4. **Versione tudo**: Git + MLflow para rastreabilidade
5. **Documente mudanÃ§as**: Mantenha README atualizado

### Estrutura de Commits

```bash
# Use conventional commits
git commit -m "feat: adiciona suporte para regressÃ£o"
git commit -m "fix: corrige encoding de features categÃ³ricas"
git commit -m "docs: atualiza README com novo dataset"
git commit -m "test: adiciona testes para novo preprocessador"
```

---

## ğŸ‰ ConclusÃ£o

VocÃª agora tem um framework completo e pronto para produÃ§Ã£o! 

**Lembre-se:**
- âœ… Comece adaptando `config.py`
- âœ… Identifique suas features
- âœ… Adapte preprocessamento e mÃ©tricas
- âœ… Teste localmente antes de push
- âœ… Use MLflow para rastrear tudo
- âœ… Mantenha >80% de cobertura de testes

**Boa sorte com seu projeto! ğŸš€**

---

**DÃºvidas?** Abra uma issue ou consulte a documentaÃ§Ã£o em [README.md](README.md)
