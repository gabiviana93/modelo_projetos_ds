# Data Science End-to-End Project Framework

[![CI Status](https://img.shields.io/badge/CI-passing-brightgreen)](https://github.com)
[![Coverage](https://img.shields.io/badge/coverage-70%25-green)](https://github.com)
[![Python](https://img.shields.io/badge/python-3.9%20%7C%203.10%20%7C%203.11-blue)](https://www.python.org/)
[![Code Quality](https://img.shields.io/badge/code%20quality-A-brightgreen)](https://github.com)

Framework completo e reutilizÃ¡vel para projetos de CiÃªncia de Dados, seguindo boas prÃ¡ticas de MLOps, com CI/CD integrado, testes automatizados e cobertura de cÃ³digo superior a 70%.

## ğŸ¯ Objetivo

Fornecer um **framework de produÃ§Ã£o** para projetos de Machine Learning com:
- âœ… Pipeline completo end-to-end
- âœ… Testes automatizados (70%+ coverage)
- âœ… CI/CD com GitHub Actions
- âœ… Rastreamento de experimentos (MLflow)
- âœ… Monitoramento de drift
- âœ… Dashboard interativo
- âœ… Logging estruturado em JSON
- âœ… DocumentaÃ§Ã£o completa

**Pronto para ser adaptado ao seu projeto!** Veja [TUTORIAL_NOVO_PROJETO.md](TUTORIAL_NOVO_PROJETO.md) para guia completo.

## ğŸ› ï¸ Stack TecnolÃ³gico

### Core
- **Python**: 3.9+ | 3.10+ | 3.11+ (testado em mÃºltiplas versÃµes)
- **Data**: Pandas 2.0+, NumPy 1.24+
- **ML**: Scikit-learn 1.3+, XGBoost 2.0+

### MLOps
- **Experimentos**: MLflow 2.22.4 (tracking, logging, model registry)
- **ValidaÃ§Ã£o**: Cross-validation com StratifiedKFold
- **Monitoramento**: PSI (Population Stability Index), Drift Detection
- **Dashboard**: Streamlit com grÃ¡ficos interativos

### Quality & Testing
- **Testes**: Pytest 7.4+ com fixtures centralizadas
- **Coverage**: pytest-cov (>70% cobertura)
- **CI/CD**: GitHub Actions (multi-version testing)
- **Linting**: Flake8, Autopep8

### Interpretabilidade & VisualizaÃ§Ã£o
- **SHAP**: Feature importance e explainability
- **Plots**: Matplotlib 3.8+, Seaborn 0.13+
- **Logging**: JSON estruturado com timestamps

### Gerenciamento
- **Ambiente**: Poetry 1.7+ (gerenciamento de dependÃªncias)
- **Versionamento**: Git + MLflow Model Registry

## Estrutura do Projeto

```
modelo_projetos_ds/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Dados brutos
â”‚   â”œâ”€â”€ processed/        # Dados processados
â”‚   â””â”€â”€ external/         # Dados externos
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb                    # AnÃ¡lise exploratÃ³ria
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb    # Engenharia de features
â”‚   â””â”€â”€ 03_modeling.ipynb              # Modelagem
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py         # ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ preprocessing.py  # Preprocessamento de dados (com logging)
â”‚   â”œâ”€â”€ features.py       # Feature engineering com SimpleImputer
â”‚   â”œâ”€â”€ train.py          # Treinamento + Cross-validation com logging
â”‚   â”œâ”€â”€ evaluate.py       # AvaliaÃ§Ã£o de mÃ©tricas com logging
â”‚   â”œâ”€â”€ monitoring.py     # Monitoramento de drift com logging
â”‚   â”œâ”€â”€ inference.py      # InferÃªncia com logging
â”‚   â”œâ”€â”€ interpret.py      # Feature importance e SHAP
â”‚   â””â”€â”€ logger.py         # Sistema genÃ©rico de logging JSON
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_pipeline.py       # Pipeline completo de produÃ§Ã£o
â”‚   â”œâ”€â”€ train_pipeline.py     # Script de treinamento com CV
â”‚   â”œâ”€â”€ test_pipeline.py      # Testes end-to-end
â”‚   â”œâ”€â”€ monitoring_pipeline.py # Monitoramento de drift
â”‚   â””â”€â”€ dashboard.py          # Dashboard Streamlit
â”œâ”€â”€ tests/                # Testes unitÃ¡rios (70%+ coverage)
â”‚   â”œâ”€â”€ conftest.py       # Fixtures compartilhadas
â”‚   â”œâ”€â”€ test_features.py
â”‚   â”œâ”€â”€ test_train.py
â”‚   â”œâ”€â”€ test_evaluate.py
â”‚   â”œâ”€â”€ test_inference.py
â”‚   â”œâ”€â”€ test_monitoring.py
â”‚   â””â”€â”€ test_logger.py
â”œâ”€â”€ models/               # Modelos treinados (versionados)
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ metrics.json      # MÃ©tricas de desempenho
â”‚   â”œâ”€â”€ drift.json        # DetecÃ§Ã£o de data drift
â”‚   â””â”€â”€ figures/          # GrÃ¡ficos e visualizaÃ§Ãµes
â”œâ”€â”€ logs/                 # Logs estruturados em JSON
â”œâ”€â”€ mlruns/               # Artefatos MLflow
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/        # CI/CD pipelines
â”‚       â”œâ”€â”€ ci.yml        # Testes e validaÃ§Ã£o
â”‚       â”œâ”€â”€ code-quality.yml
â”‚       â””â”€â”€ pr-analysis.yml
â”œâ”€â”€ pyproject.toml        # ConfiguraÃ§Ã£o Poetry
â”œâ”€â”€ pytest.ini            # ConfiguraÃ§Ã£o pytest
â”œâ”€â”€ requirements.txt      # DependÃªncias pip
â”œâ”€â”€ generate_data.py      # Gerador de dados sintÃ©ticos
â”œâ”€â”€ test_ci_locally.sh    # Script para testar CI localmente
â”œâ”€â”€ POETRY_GUIDE.md       # Guia de uso do Poetry
â”œâ”€â”€ TUTORIAL_NOVO_PROJETO.md  # Como adaptar para novo projeto
â””â”€â”€ README.md             # Este arquivo
```

## InstalaÃ§Ã£o

### OpÃ§Ã£o 1: Poetry (Recomendado)

```bash
# Instalar dependÃªncias e criar ambiente virtual
poetry install

# Ativar ambiente virtual
poetry shell

# Ou executar comandos sem ativar
poetry run python scripts/run_pipeline.py
```

### OpÃ§Ã£o 2: Pip + Venv

```bash
# Criar e ativar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows

# Instalar dependÃªncias
pip install -r requirements.txt
```

## Guia RÃ¡pido

### 1. Gerar Dados de Teste

```bash
poetry run python generate_data.py
```

Gera 500 amostras com:
- 5 features numÃ©ricas
- 3 features categÃ³ricas
- Target binÃ¡rio (classificaÃ§Ã£o)

Salva em:
- `data/raw/raw_data.csv` - Dados brutos
- `data/processed/data.csv` - Dados processados

### 2. Executar Pipeline Completo

```bash
# Com Poetry
poetry run python scripts/run_pipeline.py

# Com pip
python scripts/run_pipeline.py
```

**O que o pipeline faz:**
1. âœ“ Carrega e preprocessa dados
2. âœ“ ConstrÃ³i preprocessador (StandardScaler + OneHotEncoder)
3. âœ“ Treina modelo XGBoost com 300 estimadores
4. âœ“ Avalia modelo (ROC-AUC, Precision, Recall, F1)
5. âœ“ Registra mÃ©tricas em `reports/metrics.json`
6. âœ“ Salva modelo com MLflow (com signature automÃ¡tica)
7. âœ“ Registra tags e parÃ¢metros no MLflow

### 3. Executar Testes End-to-End

```bash
poetry run python scripts/test_pipeline.py
```

Executa teste completo com dados sintÃ©ticos:
- GeraÃ§Ã£o de dados
- DivisÃ£o treino/teste
- Treinamento
- AvaliaÃ§Ã£o
- InferÃªncia em amostras
- Rastreamento com MLflow

### 4. Visualizar Resultados com MLflow

```bash
mlflow ui --host 127.0.0.1 --port 5000
```

Acesse `http://127.0.0.1:5000` para ver:
- âœ“ ParÃ¢metros do modelo
- âœ“ MÃ©tricas de desempenho
- âœ“ Artefatos salvos (modelo + preprocessador)
- âœ“ Tags e descriÃ§Ã£o do modelo
- âœ“ HistÃ³rico de todas as runs
- âœ“ ComparaÃ§Ã£o entre experimentos

## ConfiguraÃ§Ã£o

Editar `src/config.py` para ajustar:

```python
# ConfiguraÃ§Ã£o de Dados
TARGET = "target"                    # Coluna alvo
TEST_SIZE = 0.2                      # 20% para teste
RANDOM_STATE = 42                    # Seed para reprodutibilidade

# ConfiguraÃ§Ã£o MLflow
MLFLOW_TRACKING_URI = "..."          # DiretÃ³rio local ou servidor remoto
MLFLOW_EXPERIMENT = "mlflow_test_experiments"
MODEL_NAME = "xgboost_classifier"

# ParÃ¢metros do XGBoost
MODEL_PARAMS = {
    "n_estimators": 300,
    "max_depth": 6,
    "learning_rate": 0.05,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "random_state": 42,
    "eval_metric": "logloss"
}
```

## ğŸ§ª Testes e Qualidade

### Executar Testes

```bash
# Todos os testes
poetry run pytest tests/ -v

# Com cobertura
poetry run pytest tests/ --cov=src --cov-report=html

# Teste especÃ­fico
poetry run pytest tests/test_train.py -v

# Testar CI localmente (recomendado antes de push)
./test_ci_locally.sh
```

### Cobertura Atual

```
Name                   Coverage
----------------------------------
src/config.py          100%
src/features.py        100%
src/inference.py       100%
src/monitoring.py      100%
src/preprocessing.py   100%
src/train.py           98%
src/evaluate.py        93%
----------------------------------
TOTAL                  70.03%
```

### CI/CD Workflows

O projeto possui 3 workflows automatizados:

1. **ci.yml** - Testes principais
   - Executa em Python 3.9, 3.10, 3.11
   - Verifica sintaxe e imports
   - Roda testes unitÃ¡rios
   - Gera relatÃ³rio de cobertura

2. **code-quality.yml** - Qualidade de cÃ³digo
   - FormataÃ§Ã£o com autopep8
   - DetecÃ§Ã£o de cÃ³digo duplicado
   - AnÃ¡lise de complexidade

3. **pr-analysis.yml** - AnÃ¡lise de PRs
   - Valida mudanÃ§as em arquivos Python
   - Executa testes impactados
   - Adiciona comentÃ¡rio automÃ¡tico no PR

## ğŸ’» Desenvolvimento

### Uso em Notebooks

Os notebooks em `notebooks/` podem ser executados para exploraÃ§Ã£o e experimentaÃ§Ã£o:

```bash
jupyter notebook notebooks/
```

- **01_eda.ipynb**: ExploraÃ§Ã£o e anÃ¡lise dos dados
- **02_feature_engineering.ipynb**: CriaÃ§Ã£o e seleÃ§Ã£o de features
- **03_modeling.ipynb**: ExperimentaÃ§Ã£o com diferentes modelos

### Adicionando Novas DependÃªncias

**Com Poetry:**
```bash
# Adicionar ao projeto
poetry add nome-do-pacote
âœ¨ Boas PrÃ¡ticas Implementadas

### ğŸ—ï¸ Arquitetura & CÃ³digo
âœ… **SeparaÃ§Ã£o clara** entre cÃ³digo de experimentaÃ§Ã£o (notebooks) e produÃ§Ã£o (scripts)  
âœ… **ConfiguraÃ§Ã£o centralizada** em `src/config.py`  
âœ… **MÃ³dulos reutilizÃ¡veis** e bem documentados  
âœ… **Type hints** e docstrings em funÃ§Ãµes crÃ­ticas

### ğŸ§ª Qualidade & Testes
âœ… **Testes unitÃ¡rios** com pytest (44 testes)  
âœ… **Cobertura de cÃ³digo** superior a 70%  
âœ… **Fixtures centralizadas** para reutilizaÃ§Ã£o  
âœ… **Testes end-to-end** para validar pipeline completo  
âœ… **CI/CD automatizado** com GitHub Actions (3 workflows)  
âœ… **Testing multi-versÃ£o** Python (3.9, 3.10, 3.11)

### ğŸ“Š MLOps & Monitoramento
âœ… **Rastreamento de experimentos** com MLflow 2.22.4  
âœ… **Versionamento automÃ¡tico** de modelos e artefatos  
âœ… **Signature automÃ¡tica** para modelos (sem warnings)  
âœ… **Tags e descriÃ§Ã£o** de modelos para rastreabilidade  
âœ… **Cross-validation** com StratifiedKFold (5-fold) e 4 mÃ©tricas  
âœ… **Monitoramento de data drift** com PSI por feature  
âœ… **Dashboard interativo** com Streamlit (mÃ©tricas, grÃ¡ficos, alertas)

### ğŸ” Interpretabilidade & Logging
âœ… **Feature Importance** nativa do XGBoost + SHAP values  
âœ… **Logging estruturado** em JSON (genÃ©rico em todos os mÃ³dulos)  
âœ… **Preprocessamento robusto** com SimpleImputer (mediana + constant)  
âœ… **RelatÃ³rios automÃ¡ticos** de mÃ©tricas e drift).

## Boas PrÃ¡ticas Implementadas

âœ… **SeparaÃ§Ã£o clara** entre cÃ³digo de experimentaÃ§Ã£o (notebooks) e produÃ§Ã£o (scripts)  
âœ… **Rastreamento de experimentos** com MLflow (versÃ£o 2.22.4)  
âœ… **Cross-validation** com StratifiedKFold (5-fold) e 4 mÃ©tricas  
âœ… **Feature Importance** nativa do XGBoost + SHAP values  
âœ… **Preprocessamento robusto** com SimpleImputer (mediana + constant)  
âœ… **Dashboard interativo** com Streamlit (mÃ©tricas, grÃ¡ficos, alertas)  
âœ… **Logging estruturado** em JSON (genÃ©rico em todos os mÃ³dulos)  
âœ… **Monitoramento de data drift** com PSI por feature  
âœ… **Versionamento automÃ¡tico** de modelos e artefatos  
âœ… **ConfiguraÃ§Ã£o centralizada** em `src/config.py`  
âœ… **Signature automÃ¡tica** para modelos (sem warnings)  
âœ… **Tags e descriÃ§Ã£o** de modelos para rastreabilidade  
âœ… **Testes end-to-end** para validar pipeline completo  
âœ… **Testes unitÃ¡rios** com pytest e fixtures centralizadas

## Fluxo de Trabalho Recomendado

### 1. ExploraÃ§Ã£o e AnÃ¡lise
```bash
jupyter notebook notebooks/01_eda.ipynb
```

### 2. ExperimentaÃ§Ã£o
```bash
jupyter notebook notebooks/03_modeling.ipynb
```

### 3. Rastreamento com MLflow
```bash
mlflow ui --host 127.0.0.1 --port 5000
```

### 4. Testes
```bash
poetry run python scripts/test_pipeline.py
```

### 5. ProduÃ§Ã£o
```bitash
poetry run python scripts/run_pipeline.py
```

### 6. Monitoramento de Drift
```bash
poetry run python scripts/monitoring_pipeline.py
```

### 7. Dashboard de Performance
```bash
poetry run streamlit run scripts/dashboard.py
```
Acesse `http://localhost:8501` para visualizar:
- MÃ©tricas em tempo real (ROC-AUC, F1, Precision, Recall)
- EvoluÃ§Ã£o temporal das mÃ©tricas
- HistÃ³rico de runs do MLflow
- Alertas automÃ¡ticos de degradaÃ§Ã£o

## Troubleshooting

### Erro: FileNotFoundError para dados
```bash
poetry run python generate_data.py
```

### Erro: "ModuleNotFoundError: No module named 'src'"
Execute os scripts **sempre** a partir do diretÃ³rio raiz do projeto:
```bash
cd /path/to/modelo_projetos_ds
poetry run python scripts/run_pipeline.py
```ğŸ“š DocumentaÃ§Ã£o Adicional

- **[TUTORIAL_NOVO_PROJETO.md](TUTORIAL_NOVO_PROJETO.md)** - ğŸŒŸ **Guia completo de adaptaÃ§Ã£o (Passo a passo)**
- **[QUICK_REFERENCE.md](QUICK_REFERENCE.md)** - âš¡ **ReferÃªncia rÃ¡pida (15 minutos)**
- **[POETRY_GUIDE.md](POETRY_GUIDE.md)** - Guia completo de uso do Poetry
- **[pyproject.toml](pyproject.toml)** - ConfiguraÃ§Ã£o de dependÃªncias e metadados
- **[pytest.ini](pytest.ini)** - ConfiguraÃ§Ã£o de testes
- **[.github/workflows/](.github/workflows/)** - Workflows de CI/CD

## ğŸš€ Como Adaptar para Seu Projeto

### InÃ­cio RÃ¡pido (15 minutos)
Veja **[QUICK_REFERENCE.md](QUICK_REFERENCE.md)** para checklist rÃ¡pido e comandos essenciais.

### Tutorial Completo (Recomendado)
Veja **[TUTORIAL_NOVO_PROJETO.md](TUTORIAL_NOVO_PROJETO.md)** que inclui:

1. âœ… Checklist de adaptaÃ§Ã£o passo a passo
2. âœ… ConfiguraÃ§Ã£o de novos datasets
3. âœ… CustomizaÃ§Ã£o de modelos e features
4. âœ… AdaptaÃ§Ã£o de testes
5. âœ… Deploy e produÃ§Ã£o
6. âœ… Exemplos prÃ¡ticos (Churn, RegressÃ£o, Multiclasse)

## ğŸ¯ Casos de Uso

Este framework pode ser adaptado para:
- ğŸ¥ ClassificaÃ§Ã£o de risco mÃ©dico
- ğŸ’³ DetecÃ§Ã£o de fraude
- ğŸ“§ ClassificaÃ§Ã£o de emails (spam)
- ğŸ  PrevisÃ£o de preÃ§os (regressÃ£o)
- ğŸ‘¥ SegmentaÃ§Ã£o de clientes
- ğŸ“Š AnÃ¡lise de sÃ©ries temporais
- ğŸ” Sistemas de recomendaÃ§Ã£o

## âœ… Checklist de Qualidade

Antes de fazer push:

```bash
# 1. Rodar testes localmente
./test_ci_locally.sh

# 2. Verificar cobertura
poetry run pytest --cov=src --cov-report=term

# 3. Verificar formataÃ§Ã£o
poetry run autopep8 --diff --recursive src/

# 4. Validar sintaxe
poetry run python -m py_compile src/*.py

# 5. Commitar e push
git add .
git commit -m "feat: sua mensagem"
git push
```

## ğŸ”„ PrÃ³ximos Passos e Melhorias

- [ ] Deploy em produÃ§Ã£o com FastAPI/Flask
- [ ] ContainerizaÃ§Ã£o com Docker
- [ ] IntegraÃ§Ã£o com evidently para drift avanÃ§ado
- [ ] Adicionar mais modelos (LightGBM, CatBoost)
- [ ] Pipeline de retreinamento automÃ¡tico
- [ ] API de inferÃªncia com documentaÃ§Ã£o Swagger
- [ ] Monitoramento em produÃ§Ã£o com Prometheus/Grafan` existe e tem permissÃµes de escrita.

### Modelo salvo sem signature (MLflow)
Certifique-se de passar `X_example` ao chamar `save_model()`:
```python
save_model(pipeline, X_example=X_test)
```

## MÃ©tricas de Desempenho

ApÃ³s executar o pipeline, verifique `reports/metrics.json`:

```json
{
    "roc_auc": 0.596,
    "report": {
        "0": {"precision": 0.47, "recall": 0.57, "f1-score": 0.51},
        "1": {"precision": 0.48, "recall": 0.37, "f1-score": 0.42},
        "accuracy": 0.47
    }
}
```

### MÃ©tricas Rastreadas no MLflow
- âœ“ ROC-AUC
- âœ“ Precision, Recall, F1-score por classe
- âœ“ NÃºmero de amostras de treinamento
- âœ“ NÃºmero de features

### Gerenciamento de projeto, Testes UnitÃ¡rios e CI
âœ”ï¸ Testes unitÃ¡rios com pytest  
âœ”ï¸ Pipeline CI com GitHub Actions  
âœ”ï¸ Coverage automatizado  
âœ”ï¸ Gerenciamento de dependÃªncias com Poetry

### Tags Registradas
- `model_type`: xgboost_classifier
- `framework`: scikit-learn
- `preprocessing`: StandardScaler + OneHotEncoder

## DocumentaÃ§Ã£o Adicional

- **[pyproject.toml](pyproject.toml)** - ConfiguraÃ§Ã£o de dependÃªncias e metadados
- **[POETRY_GUIDE.md](POETRY_GUIDE.md)** - Guia completo de uso do Poetry
- **[SOLUTION_SUMMARY.md](SOLUTION_SUMMARY.md)** - Resumo tÃ©cnico da soluÃ§Ã£o

## PrÃ³ximos Passos

- [ ] Integrar validaÃ§Ã£o com evidently para detectar data drift
- [ ] Adicionar testes unitÃ¡rios com pytest
- [ ] Implementar CI/CD com GitHub Actions
- [ ] Deploy em produÃ§Ã£o com FastAPI
- [ ] Criar dashboard com Streamlit
- [ ] Adicionar log e tratamento de erros
- [ ] Documentar API de inferÃªncia

## LicenÃ§a

MIT License - Veja [LICENSE](LICENSE) para detalhes

## Autor

Gabriela - 2026
